{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine, Data and Learning\n",
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vasu Singhal (2018101074)**\n",
    "\n",
    "**Tanish Lad (2018114005)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required modules and the client_moodle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client_moodle import *\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k represents the population size. We initially tried k = 4 but that turned out to be inefficient due to less randomness during crossover. Ideally, we would have loved to chose k = 16, but due to availability of less number of requests per day, we settled for k = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we were not sure how many generations will the algorithm take to converge. We experimented with a large number of values wherein we saw different kinds of results, but, we observed that letting the algorithm run for 200 generations proved to be good to see noteworthy improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our team's secret key. Our team number is **43**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_key = 'A51UvRlUeV9TMY3xKjLgA3J4yvKFG4GfZwHqoORuGtH7S2Xkn0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the best coefficients we had got from the previous run of the code. If there were less than 10 (k = 10) stored, we filled the remaining vectors with the best vector (which gave the greatest fitness). In the end, state is a list containing of 'k' vectors. It represents the population in the context of Genetic Algorithm. For the first run of the code, initial_coefficients was the overfit vector given to us. The initial population was the overfit vector repeated k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_coefficients = json.load(open(\"coefficients.txt\"))\n",
    "init = []\n",
    "\n",
    "min_error = (1e12, 1e12)\n",
    "best_coeff = []\n",
    "errors = []\n",
    "\n",
    "ratio = 1\n",
    "\n",
    "for i in initial_coefficients:\n",
    "    if min_error > (float(abs(5 * initial_coefficients[i][0] + ratio * initial_coefficients[i][1]) + 0 * abs(initial_coefficients[i][0] - ratio * initial_coefficients[i][1])), float(abs(initial_coefficients[i][0] + ratio * initial_coefficients[i][1]))):\n",
    "        min_error = (float(abs(5 * initial_coefficients[i][0] + ratio * initial_coefficients[i][1]) + 0 * abs(initial_coefficients[i][0] - ratio * initial_coefficients[i][1])), float(abs(initial_coefficients[i][0] + ratio * initial_coefficients[i][1])))\n",
    "\n",
    "        best_coeff = i.strip('][').split(', ')\n",
    "        both_errors = (initial_coefficients[i][0], initial_coefficients[i][1])\n",
    "\n",
    "    init.append(list(map(float, i.strip('][').split(', '))))\n",
    "\n",
    "    errors.append(((float(abs(5 * initial_coefficients[i][0] + ratio * initial_coefficients[i][1]) + 0 * abs(initial_coefficients[i][0] - ratio * initial_coefficients[i][1])), float(abs(initial_coefficients[i][0] + ratio * initial_coefficients[i][1]))), list(map(\n",
    "        float, i.strip('][').split(', '))), (initial_coefficients[i][0], initial_coefficients[i][1])))\n",
    "\n",
    "while len(init) < k:\n",
    "    init.append(list(map(float, best_coeff)))\n",
    "    errors.append((min_error, list(map(float, best_coeff)), both_errors))\n",
    "\n",
    "state = [init[j] for j in range(k)\n",
    "\n",
    "# print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just a dummy function to check if our code did not give any compilation or runtime errors after we make some changes in the code. This replaced the get_errors function in the client_moodle file. This was done to prevent loss of requests (because requests were limited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_errors(id, vector):\n",
    "#     return [1, 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was unarguably the most important part of our implementation of the Genetic Algorithm. All our variations in the coefficients can be traced back to this function. This function went through a lot of changes before we finally settled for the following.\n",
    "\n",
    "Initially, we were doing what the textbook said: mutate with a very small probability, and to mutate, select a random index and replace the value of the coefficient of that index with a completely random value. But soon, we realised that this is proving to be a lot inefficient and was wasting our requests.\n",
    "\n",
    "Next, we tried to always mutate - keep the mutation probability to be 1.0. But still, we were not getting results as we had expected. Those were the days when we had only 200 requests per day (Yes, we had started that early :)), so we could not do much in a day.\n",
    "\n",
    "Then, we thought why was the algorithm not giving us good results. We realised that changing the coefficient directly with a random value was leading to a lot of variation. So what we did then was, instead of replacing the coefficient with a completely random value, we should add/subtract the coefficient with a small value within a range. \n",
    "\n",
    "Firstly, we thought the range [-2, 2] is sufficiently small to be honest. Later did we realise that it is a very very large range and is creating a lot of ruckus. We then tried the range [-0.01, 0.01]. Even that didnt work very well. We then observed our coefficients. Most of them were in the range of 1e-12s or 1e-13s. So we decided to keep the range very small. We settled on [-1e13, 1e13].\n",
    "\n",
    "It started to give pretty good results. We were happy. But, then, after some days, we got stuck. Our errors were not decreasing and it got stuck in a local minima. We tried many things, but nothing worked. // More to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_range = 1e-13\n",
    "\n",
    "def mutate(child):\n",
    "    no_of_mutation = random.randint(1, 6)\n",
    "\n",
    "    for i in range(no_of_mutation):\n",
    "        index = random.randint(0, 10)\n",
    "\n",
    "        new_val = random.uniform(-5, 5)\n",
    "        new_val /= 100\n",
    "        new_val *= child[index]\n",
    "\n",
    "        child[index] += new_val\n",
    "        child[index] = max(child[index], -10)\n",
    "        child[index] = min(child[index], 10)\n",
    "\n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
